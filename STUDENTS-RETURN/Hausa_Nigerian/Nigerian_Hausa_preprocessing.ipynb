{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint, uniform\n",
    "import re\n",
    "import numpy as np\n",
    "import wave\n",
    "import contextlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './wiki_00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-717dd6a875ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./wiki_00\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[A-Za-z0-9,.\\(\\)\\\"\\\":;]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './wiki_00'"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "n=10000\n",
    "\n",
    "with open(\"./wiki_00\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = re.sub(\"[A-Za-z0-9,.\\(\\)\\\"\\\":;]\",\"\",line)\n",
    "        line=line.split()\n",
    "        i=0\n",
    "        if n<=0:\n",
    "            break\n",
    "        p=uniform(0,1)\n",
    "        if p>0.1:\n",
    "            continue\n",
    "        while i<len(line) and n>0:\n",
    "            window = randint(10,20)\n",
    "            sentence = line[i:i+window]\n",
    "            i+=window\n",
    "            if len(sentence)<5:\n",
    "                continue\n",
    "            result.append(\" \".join(sentence))\n",
    "            n-=1\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"abubakr_text.txt\",\"w\") as out:\n",
    "    out.write(\" ## si \\n\".join(result)+\" ## si\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating recordings lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total is  4979.588625000001  s ,  1.3832190625000003  h\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total = 0\n",
    "corrupted=0\n",
    "files=0\n",
    "for directory in os.listdir(\"./recordings/\"):\n",
    "    if os.path.isdir(\"./recordings/\"+directory):\n",
    "        for file in os.listdir(\"./recordings/\"+directory):\n",
    "            if file.endswith(\".wav\"):\n",
    "                files+=1\n",
    "                fname = \"./recordings/\"+directory+\"/\"+file\n",
    "                try:\n",
    "                    with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "                        frames = f.getnframes()\n",
    "                        rate = f.getframerate()\n",
    "                        duration = frames / float(rate)\n",
    "                        total+=duration\n",
    "                except Exception as e:\n",
    "                    corrupted+=1\n",
    "\n",
    "print(\"total is \",total,\" s\",\", \",total/(60*60),\" h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(files)\n",
    "print(corrupted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spliting records to train, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the non-corrupted files\n",
    "wav_files = []\n",
    "linker = []\n",
    "for directory in os.listdir(\"./recordings/\"): # parent directory of the recordings, it should contain folders that contain wav,json and txt files\n",
    "    if os.path.isdir(\"./recordings/\"+directory):\n",
    "        to_remove = []\n",
    "        for file in os.listdir(\"./recordings/\"+directory):\n",
    "            if file.endswith(\".txt\"):\n",
    "                linker_data = open(\"./recordings/\"+directory+\"/\"+file).readlines()\n",
    "            if file.endswith(\".wav\"):\n",
    "                fname = \"./recordings/\"+directory+\"/\"+file\n",
    "                try:\n",
    "                    with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "                        frames = f.getnframes()\n",
    "                        rate = f.getframerate()\n",
    "                        duration = frames / float(rate)\n",
    "                        wav_files.append(fname)\n",
    "                except Exception as e:\n",
    "                    to_remove.append(file)\n",
    "        for file in to_remove:\n",
    "            i=0\n",
    "            while i<len(linker_data):\n",
    "                if file in linker_data[i]:\n",
    "                    linker_data.pop(i)\n",
    "                i+=1\n",
    "        linker.extend(linker_data)\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_copy = \" \".join(wav_files)\n",
    "!cp -t data/records/ {to_copy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,link in enumerate(linker):\n",
    "    line = link.split(\";\")[0].split(\"(\")[1].split(\")\")[0].strip()\n",
    "    wav = link.split(\";\")[1].strip().split(\"/\")[-1]\n",
    "    linker[i] = wav+\":\"+line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_linker = open(\"./data/linker.txt\",\"w\")\n",
    "out_linker.write(\"\\n\".join(linker))\n",
    "out_linker.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data/records/train\n",
    "!mkdir ./data/records/test\n",
    "!mkdir ./data/records/val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(wav_files))\n",
    "\n",
    "test_idx = indices[:len(indices)//2]\n",
    "validation_portion = int(len(indices)//2 * 0.2)\n",
    "train_idx = indices[len(indices)//2:-validation_portion]\n",
    "valid_idx = indices[-validation_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_files = [wav_files[i].split(\"/\")[-1] for i in train_idx]\n",
    "valid_set_files = [wav_files[i].split(\"/\")[-1] for i in valid_idx]\n",
    "test_set_files = [wav_files[i].split(\"/\")[-1] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_copy_train = \"./data/records/\" + \" ./data/records/\".join(train_set_files)\n",
    "to_copy_valid = \"./data/records/\" + \" ./data/records/\".join(valid_set_files)\n",
    "to_copy_test = \"./data/records/\" + \" ./data/records/\".join(test_set_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv -t data/records/train/ {to_copy_train}\n",
    "!mv -t data/records/val/ {to_copy_valid}\n",
    "!mv -t data/records/test/ {to_copy_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making of chars.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text_file = open(\"./text.txt\",\"r\").readlines() # Modify this to the directory of your txt file that you recorded with\n",
    "text_data = []\n",
    "chars = {\" \":1,\"ε\":0}\n",
    "char_idx = 2\n",
    "for link in linker:\n",
    "    file,idx = link.split(\":\")[0],int(link.split(\":\")[1].split(\" \")[1])-1\n",
    "    line = text_file[idx]\n",
    "    line = line.split(\"##\")[0].strip()\n",
    "    line = re.sub(\"[\\[\\]|٪%«»_ـ]\",\"\",line) # Clean unnecessary characters from the data, this is for arabic\n",
    "    line = re.sub(\"[,،;؛μ\\\\\\/≈٠١٢٣٤٥٦٧٨٩τα'ίηο–ēιäɛθκ\\(\\)?”“:’.-]\",\"\",line) # Clean unnecessary characters from the data, this is for arabic\n",
    "    line = re.sub('[\"]',\"\",line) # Clean unnecessary characters from the data, this is for arabic\n",
    "    text_data.append((line,file.split(\".\")[0]))\n",
    "    char_set = set(line)\n",
    "    for c in char_set:\n",
    "        if c not in chars:\n",
    "            chars[c]=char_idx\n",
    "            char_idx+=1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_text = \"\\n\".join([wav+\":\"+line for line,wav in text_data])\n",
    "with open(\"data/raw_text_file.txt\",\"w\") as f:\n",
    "    f.write(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_text = []\n",
    "for line,wav in text_data:\n",
    "    line = list(line)\n",
    "    indicies = []\n",
    "    for c in line:\n",
    "        indicies.append(str(chars[c]))\n",
    "    indices_text.append(wav+\" \"+\" \".join(indicies))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies_text = \"\\n\".join(indices_text)\n",
    "with open(\"data/chars.txt\",\"w\") as f:\n",
    "    f.write(indicies_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/charset.json\",\"w\") as js:\n",
    "    js.write(str(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/charset.json\") as js:\n",
    "    charset = eval(js.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'ε': 0,\n",
       " 'e': 2,\n",
       " 'k': 3,\n",
       " 'i': 4,\n",
       " 'w': 5,\n",
       " 'z': 6,\n",
       " 'H': 7,\n",
       " 'h': 8,\n",
       " 's': 9,\n",
       " 'a': 10,\n",
       " 'y': 11,\n",
       " 'd': 12,\n",
       " 't': 13,\n",
       " 'ƙ': 14,\n",
       " 'u': 15,\n",
       " 'm': 16,\n",
       " 'b': 17,\n",
       " 'n': 18,\n",
       " 'r': 19,\n",
       " 'l': 20,\n",
       " 'W': 21,\n",
       " 'S': 22,\n",
       " 'K': 23,\n",
       " 'R': 24,\n",
       " 'g': 25,\n",
       " 'F': 26,\n",
       " 'j': 27,\n",
       " 'o': 28,\n",
       " 'f': 29,\n",
       " 'A': 30,\n",
       " 'ɓ': 31,\n",
       " 'T': 32,\n",
       " 'D': 33,\n",
       " 'Z': 34,\n",
       " 'J': 35,\n",
       " 'c': 36,\n",
       " 'M': 37,\n",
       " 'N': 38,\n",
       " 'B': 39,\n",
       " '8': 40,\n",
       " '7': 41,\n",
       " '1': 42,\n",
       " 'Ɗ': 43,\n",
       " '0': 44,\n",
       " '9': 45,\n",
       " 'ɗ': 46,\n",
       " 'Y': 47,\n",
       " 'I': 48,\n",
       " '‘': 49,\n",
       " 'U': 50,\n",
       " '4': 51,\n",
       " '6': 52,\n",
       " 'G': 53,\n",
       " '5': 54,\n",
       " '2': 55,\n",
       " 'Ƙ': 56,\n",
       " '3': 57,\n",
       " 'L': 58,\n",
       " 'C': 59,\n",
       " 'E': 60,\n",
       " 'P': 61,\n",
       " 'v': 62,\n",
       " 'p': 63,\n",
       " 'q': 64,\n",
       " 'O': 65}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
